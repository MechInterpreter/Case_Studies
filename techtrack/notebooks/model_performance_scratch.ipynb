{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6233ea0d-3093-4461-97eb-9436f389f869",
   "metadata": {},
   "source": [
    "# Waldemar Chang - Assignment 4: Constructing the Inference Service\n",
    "## EN.705.603.82.FA24 Creating AI-Enabled Systems\n",
    "### Task 5\n",
    "#### Using a notebook called model_performance.ipynb, analyze the performance of the two models provided to you. Use the TechTrack Dataset to perform this analysis. Finally, provide a thorough argument on why you favor one model over another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbd808-0b34-43b1-bc76-7ab2eb17976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nms import filter\n",
    "from object_detection import Model, draw_bboxes\n",
    "from helper import calculate_iou, calculate_pr, calculate_ap, calculate_map, calculate_11pi, calculate_precision_recall_f1, calculate_specificity, get_ground_truth, denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58ab0e-0a90-4953-b13e-92c707ddb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to folder containing images and labels\n",
    "folder_path = r\"C:\\Users\\walde\\techtrack\\notebooks\\logistics\"\n",
    "\n",
    "# Initialize models\n",
    "m1 = Model('model1.cfg', 'model1.weights')\n",
    "m2 = Model('model2.cfg', 'model2.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28e1c9-65f4-4587-a0d6-67fa17a6c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image file names\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "\n",
    "# Randomly select 10 images\n",
    "random.seed(42)\n",
    "sample_size = 10\n",
    "sampled_images = random.sample(image_files, sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc2d68-1b43-4cea-9a40-a4ed07d0cf42",
   "metadata": {},
   "source": [
    "#### 100 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be9060-1f10-4207-b11f-05e1e10b3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all files in the directory\n",
    "for file_name in sampled_images:\n",
    "    if file_name.endswith('.jpg'):\n",
    "        # Get base name without the extension\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        \n",
    "        # Define corresponding text file path\n",
    "        text_file = os.path.join(folder_path, f\"{base_name}.txt\")\n",
    "        \n",
    "        # Check if corresponding text file exists\n",
    "        if os.path.exists(text_file):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            image = cv.imread(image_path)\n",
    "            \n",
    "            # Read ground truth data\n",
    "            ground_truth = get_ground_truth(text_file)\n",
    "            gt_bboxes = [bbox for _, bbox in ground_truth]\n",
    "            gt_class_ids = [class_id for class_id, _ in ground_truth]\n",
    "            \n",
    "            # Perform first model's NMS filtered prediction here\n",
    "            m1_pp_frame, m1_og_frame = m1.preprocess(image)\n",
    "            m1_pred_bboxes, m1_pred_class_ids, m1_pred_scores = m1.predict(m1_pp_frame)\n",
    "            m1_post_bboxes, m1_post_class_ids, m1_post_scores = m1.post_process(m1_pred_bboxes, m1_pred_class_ids, m1_pred_scores, m1_og_frame)\n",
    "            m1_nms_bboxes, m1_nms_class_ids, m1_nms_labels, m1_nms_scores = filter(m1_post_bboxes, m1_post_class_ids, m1_post_scores, 0.5, 0.4)\n",
    "\n",
    "            # Perform second model's NMS filtered prediction here\n",
    "            m2_pp_frame, m2_og_frame = m2.preprocess(image)\n",
    "            m2_pred_bboxes, m2_pred_class_ids, m2_pred_scores = m2.predict(m2_pp_frame)\n",
    "            m2_post_bboxes, m2_post_class_ids, m2_post_scores = m2.post_process(m2_pred_bboxes, m2_pred_class_ids, m2_pred_scores, m2_og_frame)\n",
    "            m2_nms_bboxes, m2_nms_class_ids, m2_nms_labels, m2_nms_scores = filter(m2_post_bboxes, m2_post_class_ids, m2_post_scores, 0.5, 0.4)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            # Calculate metrics for Model 1\n",
    "            precision_m1, recall_m1 = calculate_pr(m1_nms_bboxes, m1_nms_class_ids, m1_nms_scores, gt_bboxes, gt_class_ids)\n",
    "            ap_m1 = calculate_ap(precision_m1, recall_m1)\n",
    "            aps_model1.append(ap_m1)\n",
    "\n",
    "            # Calculate metrics for Model 2\n",
    "            precision_m2, recall_m2 = calculate_pr(m2_nms_bboxes, m2_nms_class_ids, m2_nms_scores, gt_bboxes, gt_class_ids)\n",
    "            ap_m2 = calculate_ap(precision_m2, recall_m2)\n",
    "            aps_model2.append(ap_m2)\n",
    "            \n",
    "            # Visualize results\n",
    "            # Draw ground truth and predicted bounding boxes on image for comparison\n",
    "            image_gt = image.copy()\n",
    "            image_gt = draw_bboxes(image_gt, gt_bboxes, gt_class_ids)\n",
    "            \n",
    "            # Draw predicted boxes for Model 1\n",
    "            image_m1 = image.copy()\n",
    "            image_m1 = draw_bboxes(image_m1, m1_nms_bboxes, m1_nms_class_ids, m1_nms_scores)\n",
    "            #image_m1 = draw_bboxes(image_m1, m1_post_bboxes, m1_post_class_ids, m1_post_scores)\n",
    "            \n",
    "            # Draw predicted boxes for Model 2\n",
    "            image_m2 = image.copy()\n",
    "            image_m2 = draw_bboxes(image_m2, m2_nms_bboxes, m2_nms_class_ids, m2_nms_scores)\n",
    "            #image_m2 = draw_bboxes(image_m2, m2_post_bboxes, m2_post_class_ids, m2_post_scores)\n",
    "            \n",
    "            # Display images side by side\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(cv.cvtColor(image_gt, cv.COLOR_BGR2RGB))\n",
    "            plt.title(\"Ground Truth\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(cv.cvtColor(image_m1, cv.COLOR_BGR2RGB))\n",
    "            plt.title(\"Model 1 Predictions\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(cv.cvtColor(image_m2, cv.COLOR_BGR2RGB))\n",
    "            plt.title(\"Model 2 Predictions\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.suptitle(f\"Comparison for {file_name}\", fontsize=16)\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            print(f\"No corresponding text file found for {file_name}\")\n",
    "            \n",
    "# Calculate mAP for both models\n",
    "mAP_model1 = calculate_map(aps_model1)\n",
    "mAP_model2 = calculate_map(aps_model2)\n",
    "\n",
    "print(f\"Model 1 mAP: {mAP_model1:.4f}\")\n",
    "print(f\"Model 2 mAP: {mAP_model2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26599ff6-797c-4dc4-8ef7-fd13a5f6fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aps_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcdb2b7-b5c8-462a-a2ed-81b0c3b8def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aps_model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
